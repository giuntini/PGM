{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "To calculate the quantum centroid, **qcentroid** you have used the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the definition of QUANTUM CENTROID ---according to Definition 3.2 of the draft [as usual]\n",
    "qcentroid=1/len_class*np.sum([proj_encoded_copies[j] for j in range(len_class)],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where **proj_encoded_copies** is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define the class of all projections  associated to the n-tensor product of the n-copies of each encoded \n",
    "# vector of the dataset [X_encoded_class is such a set]\n",
    "proj_encoded_copies=[proj(fast_n_kron(fast_n_copies(vector,self.n_copies))) for vector in X_encoded_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **proj_encoded_copies** code above includes calculating the projections using the **proj()** function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of Projection operator (matrix)\n",
    "def proj(vector):\n",
    "    result=np.outer(normalize(np.conj(vector)),normalize(vector))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, according to Definition 3.2 in the draft paper, the definition of the quantum centroid is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\rho_{i} = \\frac{1}{M_{\\lambda_{i}}} \\sum_{}^{} \\{\\rho\\}_{\\lambda_{i}}$\n",
    "\n",
    "or with n_copies:\n",
    "\n",
    "<sup>(n)</sup>$\\rho_{i} = \\frac{1}{M_{\\lambda_{i}}} \\sum_{}^{} \\{\\rho^{(n)}\\}_{\\lambda_{i}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\rho$ is the quantum densities. \n",
    "\n",
    "ie. according to Definition 3.2, the calculation of the quantum centroid is just summing all the quantum densities and dividing by the class cardinality. This *does not* involve calculation of projections like you have in your code above for **qcentroid** (which uses **proj_encoded_copies**, which in turn includes calculating the projections using the **proj()** function). \n",
    "\n",
    "Can you confirm which is the correct definition for calculating the quantum centroids?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "To calculate the trace/probability values in **trace_class**, you have used the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we calculate the probability that each pgm[i] (our G_i  of the draft) assigns to each projection determined \n",
    "# by an encoded vectoors (an element of X_encoded)\n",
    "trace_class=[np.trace(np.dot(self.pgm[i],proj(fast_n_kron(fast_n_copies(enc_vector, self.n_copies))))) for enc_vector in X_encoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above includes the **proj()** function to calculate the trace/probability values. However, according to the draft paper, under pg. 5, in the first sentence at the top, the trace/probability values are calculated as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Tr(G_{\\lambda_{i}} \\cdot \\rho_{\\vec{y}})$\n",
    "\n",
    "or for n_copies:\n",
    "\n",
    "$Tr(^{(n)}G_{\\lambda_{i}} \\cdot^{(n)} \\rho_{\\vec{y}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\rho_{\\vec{y}}$ is the quantum densities.\n",
    "\n",
    "ie. according to the draft paper, the calculation of the trace/probability values is just calculating the trace/probability values of the product of $G_{\\lambda_{i}}$ and $\\rho_{\\vec{y}}$. This *does not* involve calculation of projections like you have in your code above for **trace_class** (which includes the **proj()** function).\n",
    "\n",
    "Can you confirm which is the correct definition for calculating the trace/probability values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
